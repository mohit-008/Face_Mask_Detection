{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4df4cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 13:00:34.929176: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8cbaab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50eac3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'Train',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32, \n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e33434ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 992 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'Test', \n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d5ab142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_set = test_datagen.flow_from_directory(\n",
    "        'Validation', \n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9557bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d4d572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cbf9d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling Layer\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "143ab0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c20d431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling Layer\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53e385b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1fb10c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd0b8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6be7a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b33ecde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_model = tf.keras.callbacks.ModelCheckpoint(filepath='best_model.keras',monitor='val_loss',verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bce8013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", #val_accuracy - for classification , val_loss - for regression\n",
    "    min_delta=0.0001,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    "    start_from_epoch=0,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e46bd502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8691 - loss: 0.2794"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to best_model.keras\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 168ms/step - accuracy: 0.8693 - loss: 0.2790 - val_accuracy: 0.9850 - val_loss: 0.0413\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9792 - loss: 0.0603\n",
      "Epoch 2: saving model to best_model.keras\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 191ms/step - accuracy: 0.9792 - loss: 0.0603 - val_accuracy: 0.9900 - val_loss: 0.0286\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9855 - loss: 0.0393\n",
      "Epoch 3: saving model to best_model.keras\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 198ms/step - accuracy: 0.9855 - loss: 0.0393 - val_accuracy: 0.9862 - val_loss: 0.0415\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9879 - loss: 0.0354\n",
      "Epoch 4: saving model to best_model.keras\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 171ms/step - accuracy: 0.9879 - loss: 0.0354 - val_accuracy: 0.9937 - val_loss: 0.0199\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9890 - loss: 0.0314\n",
      "Epoch 5: saving model to best_model.keras\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 196ms/step - accuracy: 0.9890 - loss: 0.0315 - val_accuracy: 0.9937 - val_loss: 0.0172\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9896 - loss: 0.0304\n",
      "Epoch 6: saving model to best_model.keras\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 173ms/step - accuracy: 0.9896 - loss: 0.0304 - val_accuracy: 0.9937 - val_loss: 0.0186\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9921 - loss: 0.0245\n",
      "Epoch 7: saving model to best_model.keras\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 179ms/step - accuracy: 0.9921 - loss: 0.0245 - val_accuracy: 0.9962 - val_loss: 0.0086\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9923 - loss: 0.0255\n",
      "Epoch 8: saving model to best_model.keras\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 180ms/step - accuracy: 0.9923 - loss: 0.0255 - val_accuracy: 0.9925 - val_loss: 0.0199\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9902 - loss: 0.0263\n",
      "Epoch 9: saving model to best_model.keras\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 171ms/step - accuracy: 0.9902 - loss: 0.0263 - val_accuracy: 0.9937 - val_loss: 0.0131\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9933 - loss: 0.0205\n",
      "Epoch 10: saving model to best_model.keras\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 160ms/step - accuracy: 0.9933 - loss: 0.0205 - val_accuracy: 0.9975 - val_loss: 0.0090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14a064dd0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=training_set,epochs=10,validation_data=validation_set,callbacks=[save_best_model,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4232bfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "test_image = image.load_img('Prediction/3.png',target_size = (64, 64))\n",
    "# test_image = image.load_img('Test/WithoutMask/1.png',target_size = (64, 64))\n",
    "# test_image = image.load_img('Test/WithMask/219.png',target_size = (64, 64))\n",
    "\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "result\n",
    "training_set.class_indices\n",
    " \n",
    "if result[0][0] == 1:\n",
    "  prediction = 'Not Have Mask'\n",
    "else:\n",
    "  prediction = 'Have Mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f424527c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Have Mask\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3905171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.9902 - loss: 0.0230\n",
      "Test accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = cnn.evaluate(test_set)\n",
    "print(f'Test accuracy: {test_accuracy:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a08e0ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(cnn,'Face Mask Detection Model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311ef71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f0856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b83269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0263f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
